---
layout: post
title: "Sklearn Priors"
---

The plan in this short note is to briefly consider how we might go about
extending the `GaussianProcessRegressor` class in the [sci-kit learn module]("")
to easy allow us to perform Gaussian process regression while specifying a prior.

First it is worth demonstrating that it is relatively simple to construct an example
of a Gaussian process for which the `maximum likelihood` value of the kernel
hyperparameter collapses to an uninteresting degerate limit

Kernel with Prior
-----------------
First step is to

Extending the GaussianProcessRegressor

```python
class GaussianProcessRegress(
    sklearn.gaussian_process.GaussianProcessRegressor):

    def log_marginal_likelihood(self, theta=None, eval_gradient=None):
        if hasattr(self.kernel, 'theta_prior'):

	    if eval_gradient:
	        ll, ll_grad = super().log_marginal_likelihood()
		lp, lp_grad = prior.logpdf(theta, eval_gradient=True)
		return ll + lp, ll_grad + lp_grad

	    else:
	        ll = super().log_marginal_likelihood()
		lp = prior.logpdf(theta)
		return ll + lp
        else:
	    return super().log_marginal_likelihood(theta, eval_gradient)
```